<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio Output Test - TTS Pattern</title>
  <style>
    body { 
      font-family: system-ui; 
      margin: 2rem; 
      max-width: 600px; 
      line-height: 1.5;
    }
    button { 
      width: 100%; 
      padding: 1rem; 
      margin: 0.5rem 0; 
      background: #007bff; 
      color: white; 
      border: none; 
      cursor: pointer; 
      font-size: 1rem;
      border-radius: 4px;
    }
    button:disabled { 
      background: #ccc; 
      cursor: not-allowed;
    }
    button:hover:not(:disabled) {
      background: #0056b3;
    }
    #log { 
      font-family: monospace; 
      background: #f5f5f5; 
      padding: 1rem; 
      height: 200px; 
      overflow-y: auto; 
      margin: 1rem 0;
      border: 1px solid #ddd;
      border-radius: 4px;
      white-space: pre-wrap;
    }
    .info {
      background: #e3f2fd;
      padding: 1rem;
      border-radius: 4px;
      margin: 1rem 0;
    }
    .device-info {
      font-size: 0.9em;
      color: #666;
      background: #f8f9fa;
      padding: 0.5rem;
      border-radius: 4px;
      margin: 1rem 0;
    }
  </style>
</head>
<body>
  <nav style="margin-bottom: 1rem;">
    <a href="../" style="color: #007bff; text-decoration: none; font-size: 0.9rem;">&larr; Comedy Colliders</a>
  </nav>
  <h1>Audio Output Test - TTS Pattern</h1>
  
  <div class="info">
    <strong>Purpose:</strong> This test replicates the exact audio playback pattern used in text-to-voice:
    <br>â€¢ Generate audio data â†’ decodeAudioData â†’ BufferSource â†’ queued playback
    <br>â€¢ Multiple audio chunks played in sequence using audioTime
  </div>

  <div class="device-info" id="deviceInfo">
    Loading device information...
  </div>

  <div id="log"></div>

  <button id="testAudio">Test TTS Audio Pattern</button>

  <script>
    const $ = id => document.getElementById(id);
    const log = $('log');
    let audioTime = 0; // Matches the TTS implementation

    function addLog(msg) {
      const lines = log.textContent.split('\n').filter(Boolean);
      const timestamp = new Date().toLocaleTimeString();
      lines.push(`[${timestamp}] ${msg}`);
      if (lines.length > 50) lines.splice(0, lines.length - 50);
      log.textContent = lines.join('\n');
      log.scrollTop = log.scrollHeight;
    }

    function detectDevice() {
      const ua = navigator.userAgent;
      const isIOS = /iPad|iPhone|iPod/.test(ua);
      const isMacOS = /Mac OS X/.test(ua) && !isIOS;
      const isSafari = /Safari/.test(ua) && !/Chrome/.test(ua);
      
      let info = `Device: ${isIOS ? 'iOS' : isMacOS ? 'macOS' : 'Other'}\n`;
      info += `Browser: ${isSafari ? 'Safari' : 'Chrome/Other'}\n`;
      info += `AudioContext: ${window.AudioContext ? 'âœ“' : 'âœ—'} webkitAudioContext: ${window.webkitAudioContext ? 'âœ“' : 'âœ—'}`;
      
      $('deviceInfo').textContent = info;
      addLog(`Device: ${isIOS ? 'iOS' : isMacOS ? 'macOS' : 'Other'}`);
    }

    // Generate a simple WAV file that can be decoded by decodeAudioData
    function generateTestWAV(frequency = 440, duration = 0.5, sampleRate = 44100) {
      const numSamples = sampleRate * duration;
      const buffer = new ArrayBuffer(44 + numSamples * 2);
      const view = new DataView(buffer);
      
      // WAV header
      const writeString = (offset, string) => {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      };
      
      writeString(0, 'RIFF');
      view.setUint32(4, 36 + numSamples * 2, true);
      writeString(8, 'WAVE');
      writeString(12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true); // PCM
      view.setUint16(22, 1, true); // Mono
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(36, 'data');
      view.setUint32(40, numSamples * 2, true);
      
      // Audio data - simple sine wave
      let offset = 44;
      for (let i = 0; i < numSamples; i++) {
        const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.3;
        view.setInt16(offset, sample * 32767, true);
        offset += 2;
      }
      
      return buffer;
    }

    // EXACT replica of the playAudio function from text-to-voice
    async function playAudio(audioData, ctx) {
      try {
        addLog('â–¶ï¸ Decoding audio data...');
        const buffer = await ctx.decodeAudioData(audioData);
        addLog(`âœ“ Decoded: ${buffer.duration.toFixed(2)}s, ${buffer.sampleRate}Hz`);
        
        const source = ctx.createBufferSource();
        source.buffer = buffer;
        source.connect(ctx.destination);
        
        const startTime = Math.max(ctx.currentTime, audioTime);
        source.start(startTime);
        audioTime = startTime + buffer.duration;
        
        addLog(`ðŸŽµ Playing at time ${startTime.toFixed(2)}s, next at ${audioTime.toFixed(2)}s`);
        
        source.onended = () => {
          addLog('âœ“ Audio chunk completed');
        };
        
      } catch (e) {
        addLog(`âŒ Audio error: ${e.message}`);
        console.error('playAudio error:', e);
      }
    }

    // Test the exact TTS pattern
    $('testAudio').onclick = async () => {
      try {
        $('testAudio').disabled = true;
        audioTime = 0; // Reset like TTS does
        
        addLog('ðŸš€ Starting TTS pattern test...');
        
        // Create AudioContext like TTS does
        const ctx = new (AudioContext || webkitAudioContext)();
        addLog(`ðŸŽ¤ AudioContext created, state: ${ctx.state}`);
        
        if (ctx.state === 'suspended') {
          await ctx.resume();
          addLog(`ðŸ”„ AudioContext resumed, new state: ${ctx.state}`);
        }
        
        // Generate 3 audio chunks to simulate streaming like TTS
        const frequencies = [440, 523, 659]; // A4, C5, E5
        const chunks = frequencies.map(freq => generateTestWAV(freq, 0.4));
        
        addLog(`ðŸ“¦ Generated ${chunks.length} audio chunks`);
        
        // Play chunks in sequence using the exact TTS pattern
        for (let i = 0; i < chunks.length; i++) {
          addLog(`Processing chunk ${i + 1}/${chunks.length}...`);
          await playAudio(chunks[i].slice(), ctx); // .slice() to copy like base64 decode does
          
          // Small delay to simulate streaming
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        addLog('âœ… All chunks queued for playback');
        
        // Re-enable button after all audio should be done
        setTimeout(() => {
          $('testAudio').disabled = false;
          addLog('ðŸ”Œ Test complete - button re-enabled');
        }, 2000);
        
      } catch (error) {
        addLog(`âŒ Test failed: ${error.message}`);
        console.error('Test error:', error);
        $('testAudio').disabled = false;
      }
    };

    // Initialize
    document.addEventListener('DOMContentLoaded', () => {
      addLog('TTS Audio Pattern Test initialized');
      detectDevice();
      
      // iOS audio unlock - create context on first touch
      document.addEventListener('touchstart', () => {
        try {
          const ctx = new (AudioContext || webkitAudioContext)();
          addLog('ðŸ“± AudioContext unlocked via touch');
          if (ctx.state === 'suspended') {
            ctx.resume().then(() => {
              addLog('ðŸ“± AudioContext resumed via touch');
            });
          }
        } catch (e) {
          addLog(`ðŸ“± Touch unlock failed: ${e.message}`);
        }
      }, { once: true });
    });
  </script>
</body>
</html>